<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="icon" sizes="64x64" href="assets/nobackfavi.ico" type="image/x-icon">\
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dish-n-Dash - Implementation</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.1/mermaid.min.js"></script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            flowchart: {
                useMaxWidth: true,
                htmlLabels: true,
                curve: 'basis',
                rankSpacing: 80,
                nodeSpacing: 80,
                padding: 40
            }
        });
    </script>
    <style>
        :root {
            --primary-color: #3b82f6;
            --secondary-color: #dbeafe;
            --text-color: #1f2937;
            --light-gray: #f3f4f6;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        }

        body {
            line-height: 1.6;
            color: var(--text-color);
        }

        .nav {
            background: white;
            padding: 1.5rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            position: fixed;
            width: 100%;
            z-index: 1000;
        }

        .nav-container {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .nav-tabs {
            display: flex;
            gap: 2rem;
        }

        .nav-tabs a {
            color: var(--text-color);
            text-decoration: none;
            font-weight: 500;
            padding: 0.5rem 0;
            border-bottom: 2px solid transparent;
            transition: all 0.3s ease;
        }

        .nav-tabs a:hover, .nav-tabs a.active {
            color: var(--primary-color);
            border-bottom: 2px solid var(--primary-color);
        }

        .header-section {
            text-align: center;
            padding: 8rem 0 2rem;
            background: var(--primary-color);
            color: white;
            margin-bottom: 3rem;
        }

        .header-section h1 {
            font-size: 2.5rem;
            margin: 0;
        }

        .header-section p {
            font-size: 1.2rem;
            margin-top: 1rem;
            opacity: 0.9;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
        }

        .implementation-card {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin: 2rem 0;
        }

        .pipeline-container {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin: 2rem 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
        }

        .mermaid {
            width: 100%;
            display: flex;
            justify-content: center;
            margin: 2rem 0;
        }

        .implementation-card img {
        width: 100%; 
        max-width: 100%; 
        height: auto; 
}

        .subsection-title {
            color: var(--primary-color);
            font-size: 1.5rem;
            margin-bottom: 1rem;
        }

        .implementation-text {
            margin: 1.5rem 0;
            line-height: 1.8;
            font-size: 1.1rem;
        }

        .component-list {
        list-style: none; 
        margin: 1.5rem 0;
        }

        .component-list li {
        margin: 1rem 0;
        padding-left: 1.5rem;
        position: relative;
        }

        .component-list li:before {
        content: ""; 
        }

        .component-list ol {
        list-style: none;
        margin-left: 1.5rem;
        counter-reset: list-counter;
        }

        .component-list ol li {
        counter-increment: list-counter;
        margin: 0.5rem 0;
        position: relative;
        }

        .component-list ol li:before {
        content: counter(list-counter) ".";
        color: var(--primary-color);
        font-weight: bold;
        position: absolute;
        left: 0;
        }

        footer {
            text-align: center;
            padding: 2rem;
            background: var(--light-gray);
            margin-top: 4rem;
        }

        code {
        font-family: 'Courier New', Courier, monospace;
        background-color: var(--light-gray);
        padding: 0.2rem 0.4rem;
        border-radius: 4px;
        font-size: 0.95em;
        color: var(--text-color);
        }

        .small-image img {
            width: 1px; 
            height: auto; 
            margin: 0.5rem 0; 
        }



        @media (max-width: 768px) {
            .nav-tabs {
                display: none;
            }
            .header-section {
                padding: 6rem 1rem 2rem;
            }
        }
    </style>
</head>
<body>
    <nav class="nav">
        <div class="nav-container">
            <a href="index.html" style="text-decoration: none; color: var(--primary-color); font-weight: bold;">Dish-n-Dash</a>
            <div class="nav-tabs">
                <a href="index.html">Home</a>
                <a href="design.html">Design</a>
                <a href="implementation.html" class="active">Implementation</a>
                <a href="results.html">Results</a>
                <a href="conclusion.html">Conclusion</a>
                <a href="materials.html">Materials</a>
            </div>
        </div>
    </nav>

    <header class="header-section">
        <h1>Implementation</h1>
        <p>A step-by-step breakdown of how Dish-n-Dash works.</p>
    </header>

    <section class="container">
        <div class="pipeline-container">
            <h2 class="subsection-title">System Pipeline</h2>
            <p class="implementation-text">The core process flow of Dish-n-Dash:</p>
            <div class="mermaid">
flowchart LR
    A[Run Image Classifier]-->B[Compute Transformations]-->C[Pick Up Bowl]-->D[Sort Contents]
    
    A1[Uses DETR model & ResNet-50<br>Locates object centroids] -.-> A
    B1[Transform coordinates<br>Generate optimal path] -.-> B
    C1[Navigate using IK<br>Grasp and lift bowl] -.-> C
    D1[Fruit → Compost<br>Utensils → Recycling] -.-> D

    classDef primary fill:#3b82f6,stroke:#2563eb,color:#fff
    classDef secondary fill:#dbeafe,stroke:#3b82f6,color:#1f2937
    
    class A,B,C,D primary
    class A1,B1,C1,D1 secondary
            </div>
        </div>

        <div class="implementation-card">
            <h2 class="subsection-title">Hardware</h2>
            <p class="implementation-text">We used the following hardware components:</p>
            <ul class="component-list">
                <li><strong>Sawyer Robot Arm</strong> </li>
                <li><strong>Intel RealSense Camera</strong> </li>
                <li><strong>Custom Sorting Bins</strong></li>
                <div class="small-img"><img src="assets/dish_compost.png"></div>
                <li><strong>Gripper Modification</strong></li>
                <div class="small-img"><img src="assets/holdingbowl.png"></div>
            </ul>
        </div>

        <div class="implementation-card">
            <h2 class="subsection-title">Data Streams</h2>
            <img src="assets/data_streams.jpg" alt="Dish-n-Dash Robot">
        </div>

        <div class="implementation-card">
            <h2 class="subsection-title">Software</h2>
            <p class="implementation-text">The software pipeline integrates the following systems:</p>
            <ul class="component-list">
                <li><strong>Object Detection:</strong>
                    In order to make our pipeline as generalizable as possible, we wanted to use an off-the-shelf image classifier called Detection Transformer (DETR). This model is able to detect hundreds of objects, including various fruit items (apple, banana, orange) and dishware (spoons, forks, plates). 
                    Our vision pipeline is the following:
                    <br>
                    <ol>
                        <li> When we run our main script, we read the first image that the camera topic receives. We refer to our local machine as the client.</li>
                        <li> We send the received image to a server in the data center. This is where the DETR model is being hosted, since we need a GPU in order to run inference. We use NGROK to facilitate this request</li>
                        <li> DETR takes this image and searches for two items. First, it searches for the bowl. Second, it searches for any of the target objects. It chooses the object with the highest confidence. We return two items: (1) the centroid of the bowl and (2) the detected object inside the bowl</li>
                        <li>Our client now knows where it should grasp the bowl and what type of object it needs to sort — in pixel space! We now need to convert this to the robot’s base frame</li>
                    </ol>
                <li><strong>Transformations:</strong> Next, we need to compute the transformation from the pixel point and to the robot gripper frame. 
                    <ol>
                        <li>We need to first calculate the transform between the pixel point and the camera frame. Using the camera intrinsic parameters, we are able to get the depth data and thus, convert the 2D pixel coordinates into 3D world point in camera frame. </li> 
                        <li>Since we had set up the camera, we had to manually calculate the transformation between the camera frame and the robot base frame by measuring the x, y, and z offset. Since the camera was oriented to point downwards towards the table, we needed to account for this 90 degree rotation in our transformation as well. This transformation is passed into the software pipeline through this line of code: <code>rosrun tf static_transform_publisher x y z 0 1.5708 0 base camera_link 100</code></li>
                        <li>Lastly, we need to transform between the robot base frame and the robot right gripper frame. This is done through the inverse kinematics pipeline.</li>
                    </ol>
                <li><strong>Trajectory Planning:</strong>
                    Now that we have our grasping point in the robot’s gripper frame, we use inverse kinematics to perform a series of motions to get to the desired location. 
                    <br>
                    <ol>
                        <li>First, we perform IK to move the robot from its initial position (which can be anywhere at the beginning) to the point transformed point that we’ve calculated using vision.</li>
                        <li>Next, we use IK to move the robot back to the tuck position, so that it can perform the rest of the motion safely. </li>
                        <li>Third, we move the point right above either the dishware or the compost bin, depending on the type of object that is detected.</li>
                        <li>Lastly, and most importantly, we computed a rotation for joint four that would allow us to get the tipping motion, such that the object drops from the bowl into the correct bin. </li>
                    </ol>
                </li>
            </ul>
        </div>
    </section>

    <footer>
        <p>© 2024 Dish-n-Dash Team. All Rights Reserved.</p>
    </footer>
</body>
</html>
